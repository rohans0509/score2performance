1. Incorporate different types of tokenization. Generate corresponding data
2. Transfer this data
3. Incorporate different types of I/O (score2perf or perf2score)
4. Incorporate different types of samplings
5. Could also have different Channel numbers as input


Tokenization

Types
-> PerformanceRNN- PerformanceRNN tokenization
-> Piano-Roll -Piano Roll tokenization
Here you could have a token for ghost note (small length, Datasets/asap-dataset/Bach/Prelude/bwv_856/midi_score.mid)
Find the nearest number to the numerator such that denominator reduces

September end NeurIPS workshop


1/24

Create colab notebook and send a zip of sample data
Testing pipeline DONE
Score2perf Training DONE
Score2melody-Check open source/ Filtering out notes with velocity (try long subsequence)
While training make a new branch and finish tokenization
Update config to indicate the tokenization
Update model on the basis of this tokenization
Train the model


Training Model : launch train.sh
sbatch train_s2p.sh
Change log file
Beam search
Update models.py from jupyter

score2perf directory etc.

Continous threshold change vs sharp jump

# Split notes based on minimum length note

Generate dataset with thresholding

Give accompaniment, model should generate melody notes

# Generate train,test data
# Check config
# Run Model

# Check notes